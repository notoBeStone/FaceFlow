//
//  FaceAnalysisViewModel.swift
//  HackWords
//
//  Created by Claude on 2025/10/26.
//

import Foundation
import SwiftUI
import SwiftData
import UIKit

@MainActor
class FaceAnalysisViewModel: ObservableObject {
    // MARK: - Published Properties
    
    @Published var isAnalyzing = false
    @Published var progress: Double = 0.0
    @Published var errorMessage: String?
    
    // MARK: - Private Properties
    
    private let faceAnalysisPrompt: String
    
    // MARK: - Initialization
    
    init() {
        self.faceAnalysisPrompt = Self.loadPrompt(filename: "FaceAnalysis")
    }
    
    // MARK: - Public Methods
    
    /// åˆ†æäººè„¸å›¾ç‰‡ï¼Œè¿”å›é¢éƒ¨å±æ€§
    func analyzeFace(_ image: UIImage) async throws -> FaceAnalysisResult {
        isAnalyzing = true
        progress = 0.0
        defer { isAnalyzing = false }
        
        do {
            // 1. å‹ç¼©å›¾ç‰‡ï¼ˆæœ€å¤§è¾¹é•¿ 1024ï¼ŒJPEG è´¨é‡ 0.8 - é¢éƒ¨åˆ†æéœ€è¦æ›´é«˜è´¨é‡ï¼‰
            progress = 0.1
            guard let imageData = compressImage(image, maxSize: 1024, quality: 0.8) else {
                throw FaceAnalysisError.imageProcessingFailed
            }
            
            debugPrint("âœ… å›¾ç‰‡å‹ç¼©å®Œæˆï¼Œå¤§å°: \(imageData.count) bytes")
            
            // 2. ä¸Šä¼ å›¾ç‰‡åˆ° S3 è·å– URL
            progress = 0.2
            let imageUrl = try await TemplateAPI.S3.upload(data: imageData, fileExtension: "jpg")
            debugPrint("âœ… å›¾ç‰‡ä¸Šä¼ æˆåŠŸï¼š\(imageUrl)")
            
            // 3. æ„å»ºæ¶ˆæ¯
            progress = 0.3
            let messages = [
                ChatGPTMessage(
                    messageId: 1,
                    role: .system,
                    content: faceAnalysisPrompt,
                    imageUrl: nil
                ),
                ChatGPTMessage(
                    messageId: 2,
                    role: .user,
                    content: nil,
                    imageUrl: imageUrl
                )
            ]
            
            // 4. è°ƒç”¨ GPT-4 Vision API
            progress = 0.4
            debugPrint("ğŸ¤– å¼€å§‹è°ƒç”¨ GPT-4 Vision API...")
            let resultJSON = try await TemplateAPI.ChatGPT.llmCompletion(
                messages,
                configuration: nil,
                responseFormat: nil
            )
            
            progress = 0.7
            debugPrint("ğŸ“ AI è¿”å›ç»“æœï¼š\(resultJSON)")
            
            // 5. æå–çº¯ JSONï¼ˆç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—ï¼‰
            let cleanJSON = extractJSON(from: resultJSON)
            debugPrint("ğŸ§¹ æ¸…æ´—åçš„ JSONï¼š\(cleanJSON)")
            
            // 6. è§£æ JSON
            progress = 0.8
            guard let jsonData = cleanJSON.data(using: .utf8) else {
                throw FaceAnalysisError.invalidJSONResponse
            }
            
            let decoder = JSONDecoder()
            let result = try decoder.decode(FaceAnalysisResult.self, from: jsonData)
            
            // 7. éªŒè¯ç»“æœæœ‰æ•ˆæ€§
            progress = 0.9
            guard result.isValid() else {
                debugPrint("âš ï¸ API è¿”å›äº†æ— æ•ˆçš„å±æ€§å€¼")
                throw FaceAnalysisError.invalidAttributeValues
            }
            
            progress = 1.0
            debugPrint("âœ… é¢éƒ¨åˆ†æå®Œæˆ")
            debugPrint("ğŸ“Š åˆ†æç»“æœ: \(result)")
            
            return result
            
        } catch let error as FaceAnalysisError {
            errorMessage = error.localizedDescription
            debugPrint("âŒ é¢éƒ¨åˆ†æå¤±è´¥ï¼š\(error)")
            throw error
        } catch {
            errorMessage = error.localizedDescription
            debugPrint("âŒ é¢éƒ¨åˆ†æå¤±è´¥ï¼š\(error)")
            throw FaceAnalysisError.analysisFailedWith(error)
        }
    }
    
    /// ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“
    func saveAnalysisResult(_ result: FaceAnalysisResult, modelContext: ModelContext) async throws {
        // è·å–æˆ–åˆ›å»º UserFaceAttributes
        let descriptor = FetchDescriptor<UserFaceAttributes>()
        let existingAttributes = try modelContext.fetch(descriptor)
        
        let attributes: UserFaceAttributes
        if let existing = existingAttributes.first {
            attributes = existing
        } else {
            attributes = UserFaceAttributes()
            modelContext.insert(attributes)
        }
        
        // æ›´æ–°ä» API è·å–çš„å±æ€§
        attributes.faceShape = result.faceShape
        attributes.cheekboneProminence = result.cheekboneProminence
        attributes.jawlineType = result.jawlineType
        attributes.chinShape = result.chinShape
        attributes.eyeSize = result.eyeSize
        attributes.eyeShape = result.eyeShape
        attributes.eyeDistance = result.eyeDistance
        attributes.eyebrowShape = result.eyebrowShape
        attributes.noseLength = result.noseLength
        attributes.noseWidth = result.noseWidth
        attributes.lipsThickness = result.lipsThickness
        attributes.lipsShape = result.lipsShape
        attributes.skinTone = result.skinTone
        attributes.skinBlemishes = result.skinBlemishes
        
        attributes.updatedAt = Date()
        
        try modelContext.save()
        
        debugPrint("âœ… é¢éƒ¨å±æ€§å·²ä¿å­˜åˆ°æ•°æ®åº“")
        debugPrint("ğŸ“Š ä¿å­˜çš„å±æ€§: \(attributes.getAllTags())")
    }
    
    // MARK: - Private Methods
    
    /// æå–çº¯ JSONï¼ˆç§»é™¤ markdown ä»£ç å—ç­‰é¢å¤–å†…å®¹ï¼‰
    private func extractJSON(from text: String) -> String {
        // å¦‚æœå·²ç»æ˜¯çº¯ JSONï¼Œç›´æ¥è¿”å›
        let trimmed = text.trimmingCharacters(in: .whitespacesAndNewlines)
        if trimmed.hasPrefix("{") && trimmed.hasSuffix("}") {
            return trimmed
        }
        
        // å°è¯•æå– markdown ä»£ç å—ä¸­çš„ JSON
        let patterns = [
            "```json\\s*\\n([\\s\\S]*?)\\n```",
            "```\\s*\\n([\\s\\S]*?)\\n```"
        ]
        
        for pattern in patterns {
            if let regex = try? NSRegularExpression(pattern: pattern, options: []),
               let match = regex.firstMatch(in: text, options: [], range: NSRange(text.startIndex..., in: text)),
               let range = Range(match.range(at: 1), in: text) {
                let extracted = String(text[range]).trimmingCharacters(in: .whitespacesAndNewlines)
                debugPrint("ğŸ” ä» markdown ä»£ç å—ä¸­æå–åˆ° JSON")
                return extracted
            }
        }
        
        // å°è¯•æŸ¥æ‰¾ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª } ä¹‹é—´çš„å†…å®¹
        if let firstBrace = text.firstIndex(of: "{"),
           let lastBrace = text.lastIndex(of: "}") {
            let jsonPart = String(text[firstBrace...lastBrace])
            debugPrint("ğŸ” é€šè¿‡å¤§æ‹¬å·æå–åˆ° JSON")
            return jsonPart
        }
        
        // å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè¿”å›åŸæ–‡æœ¬
        debugPrint("âš ï¸ æ— æ³•æå– JSONï¼Œè¿”å›åŸæ–‡æœ¬")
        return text
    }
    
    /// åŠ è½½ Prompt æ–‡ä»¶
    private static func loadPrompt(filename: String) -> String {
        guard let url = Bundle.main.url(forResource: filename, withExtension: "text"),
              let content = try? String(contentsOf: url) else {
            debugPrint("âš ï¸ æ— æ³•åŠ è½½ Prompt æ–‡ä»¶: \(filename).text")
            return ""
        }
        return content
    }
    
    /// å‹ç¼©å›¾ç‰‡
    private func compressImage(_ image: UIImage, maxSize: CGFloat = 1024, quality: CGFloat = 0.8) -> Data? {
        let size = image.size
        
        // è®¡ç®—æ–°å°ºå¯¸
        var newSize = size
        if size.width > maxSize || size.height > maxSize {
            let ratio = size.width / size.height
            if ratio > 1 {
                newSize = CGSize(width: maxSize, height: maxSize / ratio)
            } else {
                newSize = CGSize(width: maxSize * ratio, height: maxSize)
            }
        }
        
        // åˆ›å»ºæ–°å›¾ç‰‡
        UIGraphicsBeginImageContextWithOptions(newSize, false, 1.0)
        image.draw(in: CGRect(origin: .zero, size: newSize))
        let resizedImage = UIGraphicsGetImageFromCurrentImageContext()
        UIGraphicsEndImageContext()
        
        // å‹ç¼©ä¸º JPEG
        return resizedImage?.jpegData(compressionQuality: quality)
    }
}

// MARK: - Error Types

enum FaceAnalysisError: LocalizedError {
    case imageProcessingFailed
    case uploadFailed(Error)
    case invalidJSONResponse
    case invalidAttributeValues
    case analysisFailedWith(Error)
    case noFaceDetected
    
    var errorDescription: String? {
        switch self {
        case .imageProcessingFailed:
            return "Failed to process the image"
        case .uploadFailed(let error):
            return "Failed to upload image: \(error.localizedDescription)"
        case .invalidJSONResponse:
            return "Invalid response from AI"
        case .invalidAttributeValues:
            return "AI returned invalid attribute values"
        case .analysisFailedWith(let error):
            return "Analysis failed: \(error.localizedDescription)"
        case .noFaceDetected:
            return "No face detected in the image"
        }
    }
}

